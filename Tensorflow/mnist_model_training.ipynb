{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Model Training\n",
    "#### Written by Ervin Mamutov - github/imervin\n",
    "\n",
    "### Introduction\n",
    "This is my jupyter notebook containing the code I used to train my Tensorflow model to predict hand drawn figures for 808. The model is trained and tested using the MNIST dataset and built using Keras with Python 3.\n",
    "\n",
    "I will not be diving into deep explanation of the things I have already covered in my [other notebook](https://github.com/ImErvin/Tensorflow-Problem-Sheet/blob/master/IrisNotebook.ipynb), make sure to check that out before reading this through this.\n",
    "\n",
    "I have adapted code from:\n",
    "\n",
    "[1] https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "[2] http://parneetk.github.io/blog/cnn-mnist/\n",
    "\n",
    "### What is MNIST?\n",
    "\n",
    "MNIST(Modified National Institute of Standards and Technology) is a sub data set of NIST(National Institute of Standards and Technology), a large database of handwritten digits. MNIST is used to train image processing systems and is basically the \"hello world\" of machine learning and computer vision.\n",
    "\n",
    "MNIST contains 60,000 training images and 10,000 testing images. Training images are used to train a system, and testing images are used to test the trained system.\n",
    "\n",
    "### Where does the MNIST dataset come from?\n",
    "\n",
    "The set of images in the MNIST database is a combination of two of NIST's databases: Special Database 1 and Special Database 3. Special Database 1 and Special Database 3 consist of digits written by high school students and employees of the United States Census Bureau, respectively.[1]\n",
    "\n",
    "\n",
    "### What is Tensorflow and Keras?\n",
    "Tensorflow is a popular software library for dataflow programming across a range of tasks. Tensorflow is open-source and is developed by the Google Brain Team. Tensorflow is a symbolic math library and is also used for machine learning applications such as neaural networks [2]. I will be using Tensorflow's Python API but it is available for a range of languages.\n",
    "\n",
    "Keras is an open source neural network library written in Python developed by a Google engineer: Francois Chollet. Keras acts like a \"library on top of a library\" as it is capable of running on top of MXNet, Deeplearning4j, Tensorflow, CNTK or Theano. Keras takes the functionality in core Tensorflow and adds a higher-level of abstraction to it, making it easier to experiment with deep neural networks [3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the MNIST dataset\n",
    "Before I can start building my model, I must first get the MNIST dataset and decode it into a format that allows me to use it later on. Luckily MNIST is quite a popular dataset for machine learning and Keras comes with MNIST pre-built with the MNIST dataset.\n",
    "\n",
    "The keras.datasets.mnist.load_data() produces 2 tuples:\n",
    "\n",
    "    x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
    "    y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,).\n",
    "\n",
    "I will be renaming x_train, x_test to training_images, testing_images and y_train, y_test to training_labels and testing_labels but it will work the same as if I kept the names as x_train etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many values in a training image? 784\n",
      "What the 8th training image looks like:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  38  43 105 255 253 253 253\n",
      "  253 253 174   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  43 139 224 226 252 253 252 252 252\n",
      "  252 252 252 158  14   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 178 252 252 252 252 253 252 252 252\n",
      "  252 252 252 252  59   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 109 252 252 230 132 133 132 132 189\n",
      "  252 252 252 252  59   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   4  29  29  24   0   0   0   0  14\n",
      "  226 252 252 172   7   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  85\n",
      "  243 252 252 144   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  88 189\n",
      "  252 252 252  14   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  91 212 247 252\n",
      "  252 252 204   9   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  32 125 193 193 193 253 252 252 252\n",
      "  238 102  28   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  45 222 252 252 252 252 253 252 252 252\n",
      "  177   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  45 223 253 253 253 253 255 253 253 253\n",
      "  253  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  31 123  52  44  44  44  44 143 252\n",
      "  252  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15 252\n",
      "  252  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86 252\n",
      "  252  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   5  75   9   0   0   0   0   0   0  98 242 252\n",
      "  252  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  61 183 252  29   0   0   0   0  18  92 239 252 252\n",
      "  243  65   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 208 252 252 147 134 134 134 134 203 253 252 252 188\n",
      "   83   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 208 252 252 252 252 252 252 252 252 253 230 153   8\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  49 157 252 252 252 252 252 217 207 146  45   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   7 103 235 252 172 103  24   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "What the 8th training image looks like as a sequence of dots and hashes:\n",
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "...........###########......\n",
      ".........##############.....\n",
      ".........##############.....\n",
      ".........##############.....\n",
      ".........####....######.....\n",
      ".................#####......\n",
      "................######......\n",
      "..............########......\n",
      ".........############.......\n",
      "........###########.........\n",
      "........############........\n",
      ".........###########........\n",
      "................####........\n",
      "................####........\n",
      "......###......#####........\n",
      ".....####....#######........\n",
      ".....##############.........\n",
      ".....#############..........\n",
      ".....###########............\n",
      "......#######...............\n",
      "............................\n",
      "............................\n",
      "............................"
     ]
    }
   ],
   "source": [
    "# Use keras's dataset mnist\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Initiate two tuples, the first with uint8 array of grayscale image data, the other with integers between 0-9\n",
    "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
    "\n",
    "print(\"How many values in a training image?\", len(training_images[7]) * len(training_images[7][0]))\n",
    "print(\"What the 8th training image looks like:\")\n",
    "print(training_images[7])\n",
    "print()\n",
    "print(\"What the 8th training image looks like as a sequence of dots and hashes:\")\n",
    "# Visualize a training image by printing out it's RGB value as a #\n",
    "for x in training_images[7]:\n",
    "    print()\n",
    "    for y in x:\n",
    "        if(y != 0):\n",
    "            print(\"#\", end=\"\")\n",
    "        else:\n",
    "            print(\".\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the array's values are displayed as integers between 0-255. There are 784 values and each value represents a pixel in the picture, the integer represents that pixel's RGB Grayscale value between 0-255. 0 means black, anything above 0 is lighter than black."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import relevant libraries\n",
    "I will need to import numpy to use numpys extensive arrays, keras to create, train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as kr #importing keras\n",
    "import numpy as np #importing numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparing the data for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/testing Images shape: (60000, 28, 28) / (10000, 28, 28)\n",
      "Training/testing Labels shape: (60000,) / (10000,)\n",
      "First 5 training labels and testing labels: [5 0 4 1 9] / [7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training/testing Images shape:\",training_images.shape,\"/\",testing_images.shape)\n",
    "print(\"Training/testing Labels shape:\",training_labels.shape,\"/\",testing_labels.shape)\n",
    "print(\"First 5 training labels and testing labels:\", training_labels[:5], \"/\", testing_labels[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output above, the shape of the image arrays is (number_of_images, 28, 28), meaning that there are 28 rows and 28 columns of pixels representing each picture. The shape of the label arrays is (number_of_labels), these labels correspond to the number_of_images in the image arrays. \n",
    "\n",
    "To prepare my data I must consider what type of architecture my neural network will have.. \n",
    "1. Basic Neural Network\n",
    "2. Convolutional Neural Network\n",
    "\n",
    "After some research I found that the basic NN works fine but limits out at around 96-97% accuracy and convolution neaural networks(CNN) hit around 99% accuracy using the same effort as you hit the point of deminishing returns sooner with an NN. [4] \n",
    "\n",
    "### Convolution\n",
    "\n",
    "From what I understand **Convolution Neaural Networks** are made for image recognition and classification purposes, inspired by the animal visual cortex. CNN works by taking an image of n x n image (MyImage) and applying a k x k filter (or convolvution kernel) then compute MyImage x Convolution Kernel by multiplying the matrices to result in a new matrice that makes up the image. Once we have a new matrice, we add a \"pooling\" layer which will take a chunk of the image and aggregate them into a single value (downsampling) [5].\n",
    "\n",
    "Here are image representations taken from [5].\n",
    "\n",
    "Convolving the image matrice\n",
    "![CNN1](https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/figures/convolve.png)\n",
    "(I = MyImage and K = Convolution Kernel)\n",
    "\n",
    "Maxpooling an chunk of the image\n",
    "![CNN2](https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/figures/pool.png)\n",
    "\n",
    "### Pre-processing arrays\n",
    "\n",
    "As I'm building a CNN, I will need to reshape my data to add a \"depth\" dimension. A full image with all 3 RGB channels will have a depth of 3, however the mnist images only have a depth of 1 (grayscale). This means I must take the shape of the image arrays (number_of_images, 28, 28) and turn it into (number_of_images,28,28,1) [6]. Numpys .reshape function allows me to give an array a new shape without changing it's data. [7] I will also be turning the data into floats as for the normalisation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape after reshape = (60000, 28, 28)\n",
      "Testing images shape after reshape = (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "training_images_rs = training_images.reshape(training_images.shape[0],28,28,1).astype(\"float32\")\n",
    "print(\"Training images shape after reshape =\",training_images.shape)\n",
    "testing_images_rs = testing_images.reshape(testing_images.shape[0],28,28,1).astype(\"float32\")\n",
    "print(\"Testing images shape after reshape =\",testing_images_rs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have added a depth channel to the shape and turned every value into a float, I can normalize the data.\n",
    "A common method of normalizing the data so that each pixel's value is between 0 and 1 is dividing each value by the maximum value that it can be (in this case 255). Another method is dividing everything by the largest value present in the dataset. In the MNIST case, there are values that are 255 and so you can hardcode it in, otherwise you could use np.max to return the largest value in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value in our training/testing images = 255.0 255.0\n",
      "Maximum value in training images before normalization: 255.0\n",
      "Maximum value in training images after normalization: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum value in our training/testing images =\", np.max(training_images_rs),np.max(testing_images_rs))\n",
    "print(\"Maximum value in training images before normalization:\", np.max(training_images_rs))\n",
    "\n",
    "training_images_rs /= 255\n",
    "testing_images_rs /= 255\n",
    "\n",
    "print(\"Maximum value in training images after normalization:\", np.max(training_images_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNSIT problem is a classification problem. This means there are multiple classes than an image can be but it cannot be two classes at once, i.e the hand drawn image of number 1 can only be 1 so it's precentage of being 0,2..9 is 0%. This can be tackled using probabilistic classification by producing a single output neuron for each class, outputting a value which corresponds to the probability of the input being of that particular class. This means that I will need to change the labels of the images (outputs) into \"one-hot\" encoding. \n",
    "\n",
    "One-hot encoding is turning a vector class intro a binary matrix for the number of classes, e.g 5 classes would be represented as [0,0,0,0,0], if each class is a fruit: an orange, banana, apple, peach and pear. A peach would be represented as [0,0,0,1,0] using one-hot encoding. This will also be used for the loss function later.\n",
    "\n",
    "Keras comes with a utility that does exactly that. The utils.to_categorical utility converts a class vector to binary class matrix [8]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The figure 3 is represented as [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.] after one-hot encoding\n"
     ]
    }
   ],
   "source": [
    "training_labels_cats = kr.utils.to_categorical(training_labels,  num_classes=10)\n",
    "testing_labels_cats = kr.utils.to_categorical(testing_labels,  num_classes=10)\n",
    "\n",
    "print(\"The figure\",training_labels[500],\"is represented as\",training_labels_cats[500],\"after one-hot encoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "Now I can begin building my Model. I will be using Keras's sequential model which is a stack of layers. I will be using the Convolution2d layers accompanied by activation, maxpooling and hidden layers. The steps involved in building my CNN are:\n",
    "1. Apply 3x3 Colvolution Kernel to 28x28 MNIST image with reLU Activation\n",
    "2. Apply 3x3 Colvolution Kernel to the image produced in 1. with reLU Activation\n",
    "3. Apply a maxpool of 2x2 to produce a downsampled image\n",
    "4. Flatten the dimensions of the image produced in 3.\n",
    "5. Preform basic NN operation on the image produced in 4. by adding a Dense layer with reLU Activation\n",
    "6. Create an output layer with 10 classes and use the Softmax Activation\n",
    "\n",
    "*Explanations for the activation functions and dense layers found in my [other notebook](https://github.com/ImErvin/Tensorflow-Problem-Sheet/blob/master/IrisNotebook.ipynb)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Shape @ Conv Layer: (None, 28, 28, 1)\n",
      "Model Output Shape @ Conv Layer: (None, 26, 26, 32) <--- Changed by Convolution layer\n",
      "Model Input Shape @ Conv Layer 2: (None, 28, 28, 1)\n",
      "Model Output Shape @ Conv Layer 2: (None, 24, 24, 32) <--- Changed by Convolution layer\n",
      "Model Input Shape @ Pooling layer: (None, 28, 28, 1)\n",
      "Model Output Shape @ Pooling layer: (None, 12, 12, 32) <--- Changed by Max Pool\n",
      "Model Input Shape @ Flatten layer: (None, 28, 28, 1)\n",
      "Model Output Shape @ Flatten layer: (None, 4608) <--- Changed by Flatten\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries for models\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense\n",
    "\n",
    "# Stacked layer model\n",
    "model = Sequential()\n",
    "# Add convolution2d layer 32 inputs, kernel size of 3x3 - activation = relu\n",
    "model.add(Convolution2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28, 28,1 )))\n",
    "print(\"Model Input Shape @ Conv Layer:\",model.input_shape)\n",
    "print(\"Model Output Shape @ Conv Layer:\",model.output_shape,\"<--- Changed by Convolution layer\")\n",
    "# Add another convolution2d layer 32 inputs, kernel size of 3x3 - activation = relu\n",
    "model.add(Convolution2D(32, kernel_size=(3, 3),activation='relu'))\n",
    "print(\"Model Input Shape @ Conv Layer 2:\",model.input_shape)\n",
    "print(\"Model Output Shape @ Conv Layer 2:\",model.output_shape,\"<--- Changed by Convolution layer\")\n",
    "# Add a MaxPooling2D pooling layer with pool size of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "print(\"Model Input Shape @ Pooling layer:\",model.input_shape)\n",
    "print(\"Model Output Shape @ Pooling layer:\",model.output_shape,\"<--- Changed by Max Pool\")\n",
    "# Flatten the data - (,12,12,32) into (,4608) - multiply each dimension to create 1 dimension only.\n",
    "model.add(Flatten())\n",
    "print(\"Model Input Shape @ Flatten layer:\",model.input_shape)\n",
    "print(\"Model Output Shape @ Flatten layer:\",model.output_shape,\"<--- Changed by Flatten\")\n",
    "# Add a hidden layer to process flattened image with relu Activation\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "# Add an output layer with softmax activation\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have defined my model, I need to compile the model and train it! I will be using categorical cross entropy as the loss function, more details about why in my [other notebook](https://github.com/ImErvin/Tensorflow-Problem-Sheet/blob/master/IrisNotebook.ipynb), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "[2] https://en.wikipedia.org/wiki/TensorFlow\n",
    "\n",
    "[3] https://en.wikipedia.org/wiki/Keras\n",
    "\n",
    "[4] https://datascience.stackexchange.com/questions/22173/why-not-use-more-than-3-hidden-layers-for-mnist-classification\n",
    "\n",
    "[5] https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/index.html\n",
    "\n",
    "[6] https://elitedatascience.com/keras-tutorial-deep-learning-in-python\n",
    "\n",
    "[7] https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.reshape.html\n",
    "\n",
    "[8] https://keras.io/utils/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
